# Préparation d'un dossier qui va contenir les données sur hdfs  
hdfs dfs -ls
hdfs dfs -mkdir /user/cloudera/datatp3

#Football Events 
wget https://www.kaggle.com/secareanualin/football-events/downloads/football-events.zip
unzip football-events.zip
#Copier les données depuis Local Vers hdfs
hdfs dfs -mkdir  /user/cloudera/datatp3/football
hdfs dfs -copyFromLocal ginf.csv events.csv dictionary.txt /user/cloudera/datatp3/football
hive
# Creation de schema ou base de données
CREATE DATABASE IF NOT EXISTS football;
SHOW DATABASES;
# Creation des tables sur hive
# Création de table events
use football;
create table events (
id_odsp string, 
id_event string,
sort_order int,
time int,
text string,
event_type int,
event_type2 int,
side int, 
event_team string,
opponent string,
player string,
player2 string,
player_in string, 
player_out string,
shot_place int,
shot_outcome int,
is_goal int,
location int,
bodypart int,
assist_method int,
situation int,
fast_break int
)
row format delimited fields terminated by ','
;

##Chargement de données vers Hive 
# Chargement table vers staging bd foot 
CREATE SCHEMA IF NOT EXISTS foot;
CREATE EXTERNAL TABLE IF NOT EXISTS foot.events (
id_odsp string, 
id_event string,
sort_order int,
time int,
text string,
event_type int,
event_type2 int,
side int, 
event_team string,
opponent string,
player string,
player2 string,
player_in string, 
player_out string,
shot_place int,
shot_outcome int,
is_goal int,
location int,
bodypart int,
assist_method int,
situation int,
fast_break int
)
 ROW FORMAT DELIMITED
 FIELDS TERMINATED BY ','
 STORED AS TEXTFILE
LOCATION '/user/cloudera/datatp3/football/';
 
 
#SELECT * FROM foot.events SORT BY id_odsp  DESC LIMIT 2;
INSERT INTO TABLE football.events SELECT * FROM foot.events;
#SELECT * FROM football.events SORT BY id_odsp  DESC LIMIT 2;
#hdfs dfs -rm /user/cloudera/datatp3/football/events.csv

#LOAD DATA INPATH '/user/cloudera/datatp3/football/events.csv' OVERWRITE INTO TABLE events;
LOAD DATA LOCAL INPATH '/home/user/cloudera/.staging/events.csv' OVERWRITE INTO TABLE football.events;
# count des records 
hive> select count(*) from events;


/********
11 unique events (1-Attempt(shot), 2-Corner, 3-Foul, 4-Yellow Card, 5-Second yellow card, 6-(Straight) red card, 7-Substitution, 8-Free kick won, 9-Offside, 10-Hand Ball, 11-Penalty conceded)
*/
select 
side
, event_team
, time
, text
from events
where event_type=11;
/*********/

/********Home teams get more penalty kicks than visitors?*******/
select 
count(side) as side
from events
where event_type=11
and text like '%draws%'
group by side
;
/*****************************************/




#chargement de table ginf
 # Création de table ginf,
use football; 
create table if not exists football.ginf (
 id_odsp string,
 link_odsp string,
 adv_stats BOOLEAN,
 date date,
 league string,
 season string,
 country string,
 ht string,
 at  string,
 fthg  int,
 ftag int,
 odd_h DOUBLE,
 odd_d DOUBLE,
 odd_a DOUBLE,
 odd_over DOUBLE,
 odd_under DOUBLE,
 odd_bts DOUBLE,
 odd_bts_n DOUBLE
)
ROW FORMAT DELIMITED
  FIELDS TERMINATED BY ','
  STORED AS TEXTFILE
 LOCATION '/user/cloudera/datatp3/football/'
;

## Staging 
CREATE EXTERNAL TABLE IF NOT EXISTS foot.ginf (
 id_odsp string,
 link_odsp string,
 adv_stats BOOLEAN,
 date date,
 league string,
 season string,
 country string,
 ht string,
 at  string,
 fthg  int,
 ftag int,
 odd_h DOUBLE,
 odd_d DOUBLE,
 odd_a DOUBLE,
 odd_over DOUBLE,
 odd_under DOUBLE,
 odd_bts DOUBLE,
 odd_bts_n DOUBLE
)
 ROW FORMAT DELIMITED
  FIELDS TERMINATED BY ','
  STORED AS TEXTFILE
 LOCATION '/user/cloudera/datatp3/football/';

SELECT * FROM foot.ginf SORT BY id_odsp  DESC LIMIT 2;
INSERT INTO TABLE football.ginf SELECT * FROM foot.ginf;
hdfs dfs -rm /user/cloudera/datatp3/football/ginf.csv

# El Classico
hive> select * from ginf where country like '%spain%' and ht like '%Barcelona%' and at like '%Real Madrid;
hive> select * from ginf where country like '%spain%' and ht like '%Real Madrid'  and at like '%Barcelona%';

select g.*, ev.*
from football.ginf as g
right join football.events as ev on (g.id_odsp=ev.id_odsp)
where g.country like '%spain%' and  g.ht like '%Barcelona%' and g.at like '%Real Madrid%'; 

# Sentiment Analysis El Classico & Jose Mourinho
select g.*, ev.text 
from football.ginf as g
right join football.events as ev on (g.id_odsp=ev.id_odsp)
where g.country like '%spain%' and  g.ht like '%Barcelona%' and g.at like '%Real Madrid%'; 


#Load Data to Pig from Hive
#Note: While loading Hive data into Pig relation, make sure that the user has started Hive metastore service using the below command –
sudo service hive-metastore start
hive –service metastore

Keep the Hive metastore service running in one terminal and use Pig in another terminal
Now to load the hive data into pig, Pig uses HCataLoader() function and it looks like this

pig
grunt > ginfpig = LOAD 'football.ginf' USING org.apache.hive.hcatalog.pig.HCatLoader();
grunt > describe ginfpig;

grunt > eventspig = LOAD 'football.events' USING org.apache.hive.hcatalog.pig.HCatLoader();
grunt > describe eventspig;

